{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pydotplus\n",
    "from sklearn import tree, preprocessing\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from scipy.sparse import csr_matrix\n",
    "from IPython.display import Image  \n",
    "#import urllib.request\n",
    "#import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jponder/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (13,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read the input\n",
    "file = \"reformatted1.csv\"\n",
    "d = pd.read_csv(file, na_values = \"null\")\n",
    "# the consumer dataset is now a Pandas DataFrame\n",
    "# Only interested in data with consumer complaints\n",
    "d = d[d['Consumer complaint narrative'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205       Capitol One 360 keeps changing what I owe on m...\n",
      "4148      I requested all XXXX reports. I got through th...\n",
      "4727      I received a forberance on my loans last sprin...\n",
      "4805      As of Tuesday; XXXX XXXX; 2017; TransUnion is ...\n",
      "5616      We sold our XXXX home on XX/XX/2016 our lender...\n",
      "13895     Re : STELLAR RECOVERY; INC ( Collection compan...\n",
      "14898     There has been a collection added to my report...\n",
      "15385     I was a victim of identity theft and noticed a...\n",
      "15853     I built my home in XXXX and had a Countrywide ...\n",
      "56784     Received Capital One charge card offer XXXX. A...\n",
      "56841     I do n't know how they got my cell number. I t...\n",
      "56891     I 'm a longtime member of Charter One Bank/RBS...\n",
      "56901     After looking at my credit report; I saw a col...\n",
      "56905     I received a call from a XXXX XXXX from XXXX @...\n",
      "56917     Was not contacted 4 years later about some pri...\n",
      "56918     Collection Consultants is reporting a collecti...\n",
      "56921     I had my purse stolen in 2007. They never foun...\n",
      "56924     I attempted to apply for a Discover Card Onlin...\n",
      "56925     Continued attempts by XXXX XXXX XXXX to collec...\n",
      "56927     This is a continuation of a previous issue wit...\n",
      "56935     Going through a divorce; my ex and I were unab...\n",
      "56937     I am assisted with my mortgage through an agen...\n",
      "56946     i submitted a payment on XXXX XXXX 2015 for my...\n",
      "56947     I recieved a notice from Midland Credit Manage...\n",
      "56963     XXXX Card services was bought out by Capital O...\n",
      "56972     I was reported late by Discover Card to the re...\n",
      "56989     XXXX i receive an email from citibank regardin...\n",
      "56990     I agreed to a settlement arrangement on a acco...\n",
      "56992     Green Tree Financial somehow got XXXX Loan AFT...\n",
      "56996     I took out a Loan from Cash Central XXXX; Al f...\n",
      "                                ...                        \n",
      "743410    I have been getting up to XXXX or more phoneca...\n",
      "743413    I took advantage of this agencies advise; and ...\n",
      "743416    I have a number of student loans that initiall...\n",
      "743430    I have had a reoccurring issue with Navient. S...\n",
      "743446    A payment {$2600.00} was sent to XXXX XXXX ( s...\n",
      "743448    The company General Revenue Corporation has be...\n",
      "743449    Navient complains that I do n't pay on time bu...\n",
      "743451    Hello; I have several outstanding loans with N...\n",
      "743457    I have been back and fourth with Navient/XXXX ...\n",
      "743458    My husband graduated during the recession; had...\n",
      "743466    XXXX XXXX keeps contacting my parents and gran...\n",
      "743469    In XXXX 2015; an automated payment to Navient ...\n",
      "743472    I speak with Naient multiple times a week rega...\n",
      "743482    I had contacted Navient today in regards to a ...\n",
      "743483    I have XXXX federal loans; XXXX XXXX XXXX loan...\n",
      "743488    XXXX XXXX XXXX defrauded over XXXX students. N...\n",
      "743492    I have a XXXX year old XXXX study loan with XX...\n",
      "743493    I graduated from XXXX XXXX in Tennessee in 201...\n",
      "743495    My student loans are from my days at the Unive...\n",
      "743505    I have been attempting to clear up old and err...\n",
      "743508    My wife and are both in repayment for our stud...\n",
      "743510    Navient is my lender for private student loans...\n",
      "743511    my school closed I was told if a school closes...\n",
      "743518    Pioneer Credit is calling my place of business...\n",
      "743523    I was making regular monthly payments to one o...\n",
      "743524    Hello; Thank you in advance for your time. Nav...\n",
      "743525    I applied for a VA refinance mortgage through ...\n",
      "743526    In XX/XX/2016 I received a mailer from Navient...\n",
      "743528    XXXX : XXXX University; XXXX; NC. \\nXXXX XXXX ...\n",
      "743531    I am have been making payments to Navient priv...\n",
      "Name: Consumer complaint narrative, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(d['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sid' 'id' 'position' 'created_at' 'created_meta' 'updated_at'\n",
      " 'updated_meta' 'meta' 'Date received' 'Product' 'Sub-product' 'Issue'\n",
      " 'Sub-issue' 'Consumer complaint narrative' 'Company public response'\n",
      " 'Company' 'State' 'ZIP code' 'Tags' 'Consumer consent provided?'\n",
      " 'Submitted via' 'Date sent to company' 'Company response to consumer'\n",
      " 'Timely response?' 'Consumer disputed?' 'Complaint ID']\n",
      "         sid                                    id  position  created_at  \\\n",
      "205   950855  ABB1397D-4223-455D-8B0E-84A3A96A9F5D    950855  1487697354   \n",
      "4148  951134  F88FDCA7-8A77-4D7B-861D-5F70AE14D65E    951134  1487697356   \n",
      "4727  951135  B6FB6CBA-54CB-4BB7-BA46-2AA71CD68962    951135  1487697356   \n",
      "4805  951136  EDD8A582-379F-486F-9D91-DE9DAEBF979C    951136  1487697356   \n",
      "5616  951137  513A2B17-783C-4138-BE94-5AEEE55597C9    951137  1487697356   \n",
      "\n",
      "      created_meta  updated_at  updated_meta  meta        Date received  \\\n",
      "205         912605  1487697354        912605   NaN  2016-12-02T23:07:58   \n",
      "4148        912605  1487697356        912605   NaN  2016-12-15T17:04:42   \n",
      "4727        912605  1487697356        912605   NaN  2016-11-13T10:30:43   \n",
      "4805        912605  1487697356        912605   NaN  2017-01-24T16:10:11   \n",
      "5616        912605  1487697356        912605   NaN  2016-12-06T17:59:47   \n",
      "\n",
      "               Product     ...      State ZIP code Tags  \\\n",
      "205      Consumer Loan     ...         OH    453XX  NaN   \n",
      "4148  Credit reporting     ...         FL    320XX  NaN   \n",
      "4727      Student loan     ...         PA    151XX  NaN   \n",
      "4805  Credit reporting     ...         AL    358XX  NaN   \n",
      "5616          Mortgage     ...         MO    630XX  NaN   \n",
      "\n",
      "     Consumer consent provided? Submitted via Date sent to company  \\\n",
      "205            Consent provided           Web  2016-12-02T23:07:59   \n",
      "4148           Consent provided           Web  2016-12-15T17:04:42   \n",
      "4727           Consent provided           Web  2016-11-15T16:04:15   \n",
      "4805           Consent provided           Web  2017-01-24T16:10:12   \n",
      "5616           Consent provided           Web  2016-12-06T17:59:47   \n",
      "\n",
      "         Company response to consumer Timely response? Consumer disputed?  \\\n",
      "205           Closed with explanation              Yes                 No   \n",
      "4148  Closed with non-monetary relief              Yes                 No   \n",
      "4727          Closed with explanation              Yes                 No   \n",
      "4805          Closed with explanation              Yes                NaN   \n",
      "5616          Closed with explanation              Yes                 No   \n",
      "\n",
      "     Complaint ID  \n",
      "205       2233355  \n",
      "4148     2252210\"  \n",
      "4727      2205926  \n",
      "4805      2308815  \n",
      "5616      2237891  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(d.columns.values)\n",
    "print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_string(my_string):\n",
    "    \"\"\" DONE. You should use this in your tokenize function.\n",
    "    \"\"\"\n",
    "    #return re.findall('[\\w\\-]+', my_string.lower())\n",
    "    #\\W -> Matches any non-alphanumeric character; \n",
    "    #this is equivalent to the class [^a-zA-Z0-9_]. \n",
    "    \n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    \n",
    "    no_numbers = my_string.lower().translate({ord(ch): None for ch in '0123456789'})\n",
    "    word_list = re.sub('\\W+', ' ', no_numbers).split()\n",
    "    stop = set(stopwords.words('english'))\n",
    "    output = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word != \"xxxx\" and word not in stop:\n",
    "            word = stemmer.stem(word)\n",
    "            if len(word) > 2:\n",
    "                output.append(word)\n",
    "            \n",
    "    word_list = output\n",
    "    \n",
    "    # preprocessing ->\n",
    "   \n",
    "    # remove too low and too high frequency words -> we can't calculate here\n",
    "\n",
    "    return(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    \"\"\"\n",
    "    Append a new column to the movies DataFrame with header 'tokens'.\n",
    "    This will contain a list of strings, one per token, extracted\n",
    "    from the 'genre' field of each movie. Use the tokenize_string method above.\n",
    "    Note: you may modify the movies parameter directly; no need to make\n",
    "    a new copy.\n",
    "    Params:\n",
    "      movies...The movies DataFrame\n",
    "    Returns:\n",
    "      The movies DataFrame, augmented to include a new column called 'tokens'.\n",
    "    >>> movies = pd.DataFrame([[123, 'Horror|Romance'], [456, 'Sci-Fi']], columns=['movieId', 'genres'])\n",
    "    >>> movies = tokenize(movies)\n",
    "    >>> movies['tokens'].tolist()\n",
    "    [['horror', 'romance'], ['sci-fi']]\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    \n",
    "    # step 1 -> do tokenize_string for each row in movies['genres']\n",
    "\n",
    "    all_words = []\n",
    "    for row in data['Consumer complaint narrative']:\n",
    "        #genre_list = re.sub(r'[||)|(]', r' ',row.lower()).split()\n",
    "        word_list = tokenize_string(row)\n",
    "        #print(word_list)\n",
    "        #print(len(genre_list))\n",
    "        all_words.append(word_list)\n",
    "    \n",
    "    # step 2 -> add column tokens in movies\n",
    "    array = np.array(all_words)\n",
    "    \n",
    "    #print(array[:5])\n",
    "    #print('#list = ',len(array))\n",
    "    \n",
    "    new_data = d.assign(tokens = array)\n",
    "    \n",
    "    #print(new_movies.head(5))\n",
    "    return(new_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featurize(data):\n",
    "    \"\"\"\n",
    "    Append a new column to the movies DataFrame with header 'features'.\n",
    "    Each row will contain a csr_matrix of shape (1, num_features). Each\n",
    "    entry in this matrix will contain the tf-idf value of the term, as\n",
    "    defined in class:\n",
    "    tfidf(i, d) := tf(i, d) / max_k tf(k, d) * log10(N/df(i))\n",
    "    where:\n",
    "    i is a term\n",
    "    d is a document (movie)\n",
    "    tf(i, d) is the frequency of term i in document d\n",
    "    max_k tf(k, d) is the maximum frequency of any term in document d\n",
    "    N is the number of documents (movies)\n",
    "    df(i) is the number of unique documents containing term i\n",
    "    Params:\n",
    "      movies...The movies DataFrame\n",
    "    Returns:\n",
    "      A tuple containing:\n",
    "      - The movies DataFrame, which has been modified to include a column named 'features'.\n",
    "      - The vocab, a dict from term to int. Make sure the vocab is sorted alphabetically as in a2 (e.g., {'aardvark': 0, 'boy': 1, ...})\n",
    "   \n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    #print(movies[:5]) \n",
    "    \n",
    "    #step 1 -> build a vocab and df(term)\n",
    "    vocab = {}\n",
    "    vocab_list = []\n",
    "    df = {}\n",
    "    \n",
    "    for tokenization in data['tokens']:\n",
    "        tokens = list(set(tokenization))\n",
    "        for term in tokens:\n",
    "            if term not in vocab.keys():\n",
    "                vocab.setdefault(term,-1)\n",
    "             \n",
    "            if term not in df.keys(): \n",
    "                df.setdefault(term,1)\n",
    "            else :\n",
    "                df[term] += 1\n",
    "             \n",
    "             \n",
    "    #print('vocab = ', vocab)\n",
    "    \n",
    "    vocab_list = sorted(vocab.keys(), key = lambda x:x)\n",
    "    #print('vocab_list = ', vocab_list)\n",
    "    \n",
    "    for i,term in enumerate(vocab_list):\n",
    "         vocab[term] = i\n",
    "            \n",
    "    #        \n",
    "         \n",
    "    #print('Sorted vocab = ', sorted(vocab.items()))\n",
    "    #print('df = ',sorted(df.items(), key=lambda x:x[0]))\n",
    "    \n",
    "    # step 2 -> Build a csr_matrix for each row of movies['tokens']\n",
    "   \n",
    "    #print('N = ',N)\n",
    "    \n",
    "    #[comedy, comedy, comedy, horror]  -> max_k tf(k, d) = 3 \n",
    "    #[action, comedy,thriller] -> tf(action, d) =1\n",
    "    # df(i) ->\n",
    "    #num_features is the total number of unique features across all documents.\n",
    "    \n",
    "    N = len(data)\n",
    "    \n",
    "    csr_array =[]\n",
    "    \n",
    "    for row1 in data['tokens']:\n",
    "        csr_row = []\n",
    "        csr_col = []\n",
    "        csr_data = []\n",
    "        max_k = 0\n",
    "       \n",
    "        max_k = Counter(row1).most_common()[:1][0][1]\n",
    "        row = list(set(row1))\n",
    "\n",
    "        #print('removed duplicates =',row)\n",
    "        for term in row:       \n",
    "            csr_row.append(0)\n",
    "            csr_col.append(vocab[term])\n",
    "            #tfidf(i, d) := tf(i, d) / max_k tf(k, d) * log10(N/df(i))\n",
    "            tf = Counter(row1)[term]\n",
    "            #max_k = max_k.most_common()[:1][0][1]\n",
    "         \n",
    "            #print('term = %s ---> tf = %d ---> max_k = %d'%(term,tf,max_k))\n",
    "            tfidf = (tf / max_k) * math.log10(N/df[term])\n",
    "            csr_data.append(tfidf)\n",
    "           \n",
    "         \n",
    "        #print('csr_row = ',csr_row) \n",
    "        #print('csr_col = ',csr_col)\n",
    "        #print('csr_data=',csr_data)\n",
    "        X = csr_matrix((csr_data, (csr_row, csr_col)), shape=(1, len(vocab)), dtype=np.float64)\n",
    "       \n",
    "        #print('X ->\\n',X.toarray())\n",
    "        csr_array.append(X)\n",
    "    \n",
    "\n",
    "    # step 3 -> add column features to movies \n",
    "    #print('size of csr_array = ',len(csr_array)) \n",
    "    #print('CSR = ',csr_array[:2])  \n",
    "    new_data = data.assign(features = csr_array)\n",
    "    #print(new_movies.head(2))\n",
    "     \n",
    "    return(new_data,vocab)   \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = tokenize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205      [capitol, one, keep, chang, owe, loan, also, c...\n",
      "4148     [request, report, got, process, fine, got, rep...\n",
      "4727     [receiv, forber, loan, last, spring, saw, rece...\n",
      "4805     [tuesday, transunion, still, know, illeg, repo...\n",
      "5616     [sold, home, lender, vanderbilt, mortgag, toda...\n",
      "13895    [stellar, recoveri, inc, collect, compani, ref...\n",
      "14898    [collect, report, bureaus, belong, collect, co...\n",
      "15385    [victim, ident, theft, notic, collect, credit,...\n",
      "15853    [built, home, countrywid, home, loan, husband,...\n",
      "56784    [receiv, capit, one, charg, card, offer, appli...\n",
      "56841    [know, got, cell, number, told, would, deal, o...\n",
      "56891    [longtim, member, charter, one, bank, rbs, cit...\n",
      "56901    [look, credit, report, saw, collect, account, ...\n",
      "56905    [receiv, call, ext, state, owe, want, howev, w...\n",
      "56917    [contact, year, later, privat, loan, suppos, t...\n",
      "56918    [collect, consult, report, collect, account, c...\n",
      "56921    [purs, stolen, never, found, person, respons, ...\n",
      "56924    [attempt, appli, discov, card, onlin, system, ...\n",
      "56925    [continu, attempt, collect, debt, name, debt, ...\n",
      "56927    [continu, previous, issu, citibank, reach, ano...\n",
      "Name: tokens, dtype: object\n",
      "743466    [keep, contact, parent, grandpar, live, comple...\n",
      "743469    [autom, payment, navient, return, insuffici, f...\n",
      "743472    [speak, naient, multipl, time, week, regard, l...\n",
      "743482    [contact, navient, today, regard, privat, stud...\n",
      "743483    [feder, loan, loan, navient, loan, payment, na...\n",
      "743488    [defraud, student, navient, attempt, collect, ...\n",
      "743492    [year, old, studi, loan, navient, appar, legal...\n",
      "743493    [graduat, tennesse, mess, grade, lost, scholar...\n",
      "743495    [student, loan, day, univers, increas, month, ...\n",
      "743505    [attempt, clear, old, erron, inform, report, s...\n",
      "743508    [wife, repay, student, loan, problem, loan, se...\n",
      "743510    [navient, lender, privat, student, loan, also,...\n",
      "743511    [school, close, told, school, close, debt, nul...\n",
      "743518    [pioneer, credit, call, place, busi, collect, ...\n",
      "743523    [make, regular, month, payment, one, collect, ...\n",
      "743524    [hello, thank, advanc, time, navient, debt, co...\n",
      "743525    [appli, refin, mortgag, loan, depot, time, pay...\n",
      "743526    [receiv, mailer, navient, list, option, reduc,...\n",
      "743528    [univers, nxxxx, gave, predict, uncollect, loa...\n",
      "743531    [make, payment, navient, privat, loan, compani...\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.head(20)['tokens'])\n",
    "print(data.tail(20)['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205     1.0\n",
      "4148    1.0\n",
      "4727    0.0\n",
      "4805    2.0\n",
      "5616    0.0\n",
      "Name: class_vector, dtype: float64\n",
      "205                      Consumer Loan-Vehicle loan\n",
      "4148                           Credit reporting-nan\n",
      "4727    Student loan-Federal student loan servicing\n",
      "4805                           Credit reporting-nan\n",
      "5616           Mortgage-Conventional fixed mortgage\n",
      "Name: combined_product, dtype: object\n",
      "205                      Taking out the loan or lease-nan\n",
      "4148    Unable to get credit report/credit score-Probl...\n",
      "4727    Dealing with my lender or servicer-Having prob...\n",
      "4805    Incorrect information on credit report-Account...\n",
      "5616         Loan servicing; payments; escrow account-nan\n",
      "Name: combined_issue, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#create new features\n",
    "class_vector = pd.factorize(data['Company response to consumer'])\n",
    "data['class_vector'] = pd.Series(class_vector[0])\n",
    "data['combined_product'] = data.apply(lambda x: \"%s-%s\" % (x['Product'], x['Sub-product']), axis = 1)\n",
    "data['combined_issue'] = data.apply(lambda x: \"%s-%s\" % (x['Issue'], x['Sub-issue']), axis = 1)\n",
    "print(data[\"class_vector\"].head())\n",
    "print(data[\"combined_product\"].head())\n",
    "print(data[\"combined_issue\"].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Student loan-Non-federal student loan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-03ea67da38e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'combined_issue'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0missue_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     ])\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn_pandas/dataframe_mapper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 _call_fit(transformers.fit,\n\u001b[0;32m--> 151\u001b[0;31m                           self._get_col_subset(X, columns), y)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# handle features not explicitly selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn_pandas/pipeline.py\u001b[0m in \u001b[0;36m_call_fit\u001b[0;34m(fit_method, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# fit takes only one argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \"\"\"\n\u001b[0;32m-> 1834\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \"\"\"\n\u001b[1;32m   1891\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 1892\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m     \"\"\"\n\u001b[0;32m-> 1697\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Student loan-Non-federal student loan'"
     ]
    }
   ],
   "source": [
    "decision_tree_data = data.ix[:, ['combined_product', 'combined_issue']]\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "product_enc = preprocessing.OneHotEncoder()\n",
    "issue_enc = preprocessing.OneHotEncoder()\n",
    "x = DataFrameMapper([\n",
    "        ('combined_product', product_enc), \n",
    "        ('combined_issue',issue_enc)\n",
    "    ])\n",
    "x_1 = x.fit_transform(decision_tree_data)\n",
    "x_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Student loan-Non-federal student loan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3c8965e79eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Company response to consumer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn_pandas/dataframe_mapper.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 _call_fit(transformers.fit,\n\u001b[0;32m--> 151\u001b[0;31m                           self._get_col_subset(X, columns), y)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# handle features not explicitly selected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn_pandas/pipeline.py\u001b[0m in \u001b[0;36m_call_fit\u001b[0;34m(fit_method, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# fit takes only one argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \"\"\"\n\u001b[0;32m-> 1834\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \"\"\"\n\u001b[1;32m   1891\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 1892\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m     \"\"\"\n\u001b[0;32m-> 1697\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jponder/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Student loan-Non-federal student loan'"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = clf.fit( x_1, y = data['Company response to consumer'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,   \n",
    "                         class_names=data['Company response to consumer'].values,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, vocab = featurize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('vocab:')\n",
    "print(sorted(vocab.items())[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
